{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123      # modifiable seed\n",
    "CLF_SS = 1      # sub-sample model types for faster run\n",
    "TARGETS = -1    # which target (0-4) to predict; -1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (15,5.5)\n",
    "\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "if SEED < 0:\n",
    "    np.random.seed(datetime.datetime.now().microsecond)\n",
    "else:\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/hiroki/share/kaggle_data/trends-assessment-prediction/'\n",
    "\n",
    "loading =  pd.read_csv(path+ '/' + 'loading.csv').set_index('Id')\n",
    "fnc =  pd.read_csv(path+ '/' + 'fnc.csv').set_index('Id')\n",
    "assert len(loading) == len(fnc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data =  pd.read_csv(path+ '/' + 'train_scores.csv').set_index('Id')\n",
    "\n",
    "data = pd.concat((loading, fnc,  ), axis = 'columns')  \n",
    "test_data = data[~data.index.isin(y_data.index)]\n",
    "\n",
    "X = data.loc[y_data.index] \n",
    "y = y_data \n",
    "groups = np.random.randint(0, 5, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, KFold, ShuffleSplit\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_params = {\n",
    "    'kernel': [  'rbf',  ] , \n",
    "    'C': [ 1, 2, 3, 5, 7, 10, 15, 20, 30, 50, 70, 100, 140, 200, 300  ],\n",
    "    'gamma': [ 'scale'], \n",
    "    'nu': [   0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1] }\n",
    "\n",
    "def trainNuSVR(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = NuSVR(cache_size=1000, tol = 1e-5)\n",
    "    params = nusvr_params        \n",
    "    return trainModel(x, y, groups, clf, params, cv, n_jobs,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_params = { 'alpha': [  1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 3e-2, 0.1, 0.3,   ],\n",
    "                'l1_ratio': [ 0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.95, 0.97, 0.98, 0.99, 1,   ]}\n",
    "\n",
    "def trainENet(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = ElasticNet(normalize = True, selection = 'random', max_iter = 10000, tol = 1e-5 )\n",
    "    return trainModel(x, y, groups, clf, enet_params, cv, n_jobs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnae(y_true, y_pred):\n",
    "    valid = ~np.isnan(y_true)\n",
    "    y_true = y_true[valid]\n",
    "    y_pred = y_pred[valid]\n",
    "    return np.sum(np.abs(y_true - y_pred))/np.sum(y_true)\n",
    "\n",
    "fnae_scorer = make_scorer(fnae, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x, y, groups, clf, params, cv = 0, n_jobs = None, \n",
    "                   verbose=0, splits=None, **kwargs):\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1    \n",
    "\n",
    "    n_iter = 30    \n",
    "        \n",
    "    folds = ShuffleSplit(n_splits = 10, train_size = 0.75, test_size = 0.20)\n",
    "    clf = RandomizedSearchCV(clf, params, cv = folds, n_iter = n_iter, \n",
    "                            verbose = 1, n_jobs = n_jobs, scoring = fnae_scorer)\n",
    "    \n",
    "    f = clf.fit(x, y, groups)\n",
    "    \n",
    "    print(pd.DataFrame(clf.cv_results_['mean_test_score'])); print();  \n",
    "    best = clf.best_estimator_;  print(best)\n",
    "    print(\"Best Score: {}\".format(np.round(clf.best_score_,4)))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanX(X, target):\n",
    "    X = X.copy()\n",
    "    \n",
    "    for col in fnc.columns:\n",
    "        X[col] = X[col] / 300\n",
    "       \n",
    "    return X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBag(n = 3, model_type = trainENet, data = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "\n",
    "    valid = ~y.isnull()\n",
    "    X = X[valid]; y = y[valid]; groups = groups[valid]\n",
    "    \n",
    "    if 'target' in kwargs:\n",
    "        X = cleanX(X, kwargs['target'])\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    clfs = []; preds = []; ys=[]; datestack = []\n",
    "    for group in group_list:\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "        \n",
    "        groups_train = groups[groups != group]\n",
    "\n",
    "        model = model_type \n",
    "        clf = model(x_train, y_train, groups_train, **kwargs) \n",
    "        clfs.append(clf)\n",
    "\n",
    "        predicted = clf.predict(x_holdout)\n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, predicted)  ) )\n",
    "        \n",
    "        preds.append(predicted)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_ho = np.concatenate(ys) \n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\nModel Bag Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBaseClfs(clfs, clf_names, data, target = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "    \n",
    "    X = cleanX(X, target)\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    X_ordered = []; y_ordered = []; groups_ordered =[]  \n",
    "    all_base_clfs = []; base_preds = [[] for i in range(0, 5 * len(clfs))]; \n",
    "    for group in group_list:\n",
    "        print(\"Training Fold {} of {}:\".format(group, len(group_list)))\n",
    "        np.random.seed(SEED)\n",
    "        \n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "\n",
    "        y_idx = ALL_TARGETS.index(target)\n",
    "        \n",
    "        X_ordered.append(x_holdout)\n",
    "        y_ordered.append(y_holdout)\n",
    "        groups_ordered.append(groups[groups == group])\n",
    "        \n",
    "        base_clfs = []\n",
    "        for idx, clf in enumerate(clfs):\n",
    "            base_clfs.append(clone(clf))\n",
    "        \n",
    "        def train_model(model, X, y):\n",
    "            ss = (~pd.DataFrame(y).isnull().any(axis=1))\n",
    "            model.fit(X[ss], y[ss]); return model\n",
    "        \n",
    "        base_clfs = Parallel(n_jobs=4)(delayed(train_model)(model, x_train, y_train[y_var]) for model in base_clfs)\n",
    "        all_base_clfs.append(base_clfs)\n",
    "        \n",
    "        def predict_model(model, X):\n",
    "            o = model.predict(X); return o    \n",
    "        preds = Parallel(n_jobs=4)(delayed(predict_model)(model, x_holdout) for model in base_clfs)\n",
    "        \n",
    "        \n",
    "        pidx = 0; clf_pred_names = []\n",
    "        for idx, clf in enumerate(base_clfs):   \n",
    "            print(\"{:.4f} for {}\".format( \n",
    "                      fnae(y_holdout[target], preds[idx]), clf_names[idx]  ) )\n",
    "            base_preds[pidx].append(preds[idx]); pidx+=1;\n",
    "            clf_pred_names.append(clf_names[idx])\n",
    "            \n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "\n",
    "    base_preds = base_preds[:len(clf_pred_names)]\n",
    "    for idx in range(0, len(base_preds)):\n",
    "        base_preds[idx] = np.concatenate(base_preds[idx])\n",
    "\n",
    "    \n",
    "    print(\"\\Base Classifier Train Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "    return (all_base_clfs, base_preds, clf_pred_names, \n",
    "        pd.concat(X_ordered), pd.concat(y_ordered), np.concatenate(groups_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lassos():\n",
    "    clfs = []; clf_names = []\n",
    "    lassos =  [1e-5, 3e-5, 1e-4,  3e-4,  0.001, 0.003,  0.01,  0.03,  0.1,  0.3,  1, ]\n",
    "    for l in lassos:\n",
    "        clfs.append(Lasso(alpha = l,  selection = 'random', max_iter = 5000, tol = 1e-5))\n",
    "        clf_names.append('Lasso alpha={}'.format(l))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    " \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridges():\n",
    "    clfs = []; clf_names = []\n",
    "    ridges =  [3e-5,  1e-4,  2e-4, 5e-4, 0.001, 0.002, 0.005,  0.01,  0.03,  0.1,  0.3,  1,  3,  10,    ]\n",
    "    for r in ridges:\n",
    "        clfs.append(Ridge(alpha = r, max_iter = 5000, tol = 1e-5))\n",
    "        clf_names.append('Ridge alpha={}'.format(r))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    "\n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVRs():\n",
    "    clfs = []; clf_names = []\n",
    "    svrs =  ([0.2, 1, 7, 50], [1, 3, 7]) \n",
    "    for c in svrs[0]:\n",
    "        for e in svrs[1]:\n",
    "            clfs.append(SVR(C = c, epsilon = e, cache_size=1000, max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('SVR C={}, epsilon={}'.format(c,e))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENets():\n",
    "    clfs = []; clf_names = []\n",
    "    enets = ([3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2  ], [ 0, 0.05, 0.1, 0.5, 0.9, 0.95, 0.98, 1]) \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = False, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet alpha={}, l1_ratio={}'.format(a,l))\n",
    " \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = True, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet-n alpha={}, l1_ratio={}'.format(a,l))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaseClfs(y_var):\n",
    "    idx = ALL_TARGETS.index(y_var)\n",
    "\n",
    "    clfs = []\n",
    "    clf_names = []\n",
    "    \n",
    "    model_sets =  [SVRs(), ENets(), Lassos(), Ridges()]\n",
    "    for model_set in model_sets:\n",
    "        clfs.extend(model_set[0])\n",
    "        clf_names.extend(model_set[1])\n",
    "   \n",
    "\n",
    "    return clfs[::CLF_SS], clf_names[::CLF_SS];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TARGETS = y.columns.to_list()  \n",
    "if isinstance(TARGETS, list):\n",
    "    targets = [ALL_TARGETS[i] for i in TARGETS]\n",
    "elif TARGETS is not None and TARGETS >= 0:\n",
    "    targets = ALL_TARGETS[TARGETS: TARGETS + 1]\n",
    "else:\n",
    "    targets = ALL_TARGETS\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaFilter(X):\n",
    "    return X[[c for c in X.columns if c not in data.columns or c in loading.columns ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Training Models for age---\n",
      "\n",
      "Training Fold 0 of 5:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f55ca12eb2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     trainBaseClfs(raw_base_clfs, base_clf_names, \n\u001b[1;32m     12\u001b[0m                                   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                   target=y_var, )\n\u001b[0m\u001b[1;32m     14\u001b[0m     Xe = pd.concat( (Xe, pd.DataFrame( dict(zip(base_clf_names, base_clf_preds)), index=Xe.index) ),\n\u001b[1;32m     15\u001b[0m                      axis = 'columns')\n",
      "\u001b[0;32m<ipython-input-17-197ee058dd44>\u001b[0m in \u001b[0;36mtrainBaseClfs\u001b[0;34m(clfs, clf_names, data, target, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mbase_clfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_clfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mall_base_clfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_clfs = []; all_raw_base_clfs = []; all_base_clfs = []; scalers = []\n",
    "for idx, y_var in enumerate(targets):\n",
    "    print('---Training Models for {}---\\n'.format(y_var))\n",
    "       \n",
    "    \n",
    "    # train base classifiers\n",
    "    raw_base_clfs, base_clf_names = getBaseClfs(y_var)\n",
    "    all_raw_base_clfs.append((raw_base_clfs, base_clf_names))\n",
    "    \n",
    "    base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge = \\\n",
    "                    trainBaseClfs(raw_base_clfs, base_clf_names, \n",
    "                                  data = (X, y, groups), \n",
    "                                  target=y_var, )\n",
    "    Xe = pd.concat( (Xe, pd.DataFrame( dict(zip(base_clf_names, base_clf_preds)), index=Xe.index) ),\n",
    "                     axis = 'columns')\n",
    "    \n",
    "    all_base_clfs.append((base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge ))\n",
    "    \n",
    "    \n",
    "    # train meta model\n",
    "    \n",
    "    if y_var == 'age':\n",
    "        s = FunctionTransformer()\n",
    "        meta_model = trainNuSVR\n",
    "    else:\n",
    "        s = StandardScaler()\n",
    "        meta_model = trainENet\n",
    "     \n",
    "    s.fit(metaFilter(Xe))\n",
    "    scalers.append(s)\n",
    "    \n",
    "    all_clfs.append( runBag(data = (s.transform(metaFilter(Xe)), ye[y_var], ge), # target=y_var,\n",
    "                                   model_type = meta_model) )\n",
    "    # run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def predictBag(X, y, groups, clfs, target = None):\n",
    "    start_time = datetime.datetime.now(); \n",
    "\n",
    "    valid = ~y.isnull()\n",
    "    X = X[valid]; y = y[valid]; groups = groups[valid]\n",
    "    \n",
    "    if target is not None:\n",
    "        X = cleanX(X, target)\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "\n",
    "    preds = []; ys=[]; datestack = []\n",
    "    for idx, group in enumerate(group_list):\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "  \n",
    "        y_pred = clfs[idx].predict(x_holdout)    \n",
    "        preds.append(y_pred)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, y_pred) ) )\n",
    "        \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(ys) \n",
    "    \n",
    "    print(\"\\Bag Prediction Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def predictAll(X_test, all_base_clfs, all_clfs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "        \n",
    "    def predict_model(model, X):\n",
    "        o = model.predict(X)\n",
    "        return o    \n",
    "    \n",
    "    all_preds = pd.DataFrame(columns = targets, index=X_test.index)\n",
    "    for tidx, y_var in enumerate(targets): # loop over targets\n",
    "        print(y_var)\n",
    "        Xi = cleanX(X_test, y_var)\n",
    "        base_clfs = all_base_clfs[tidx][0]\n",
    "         \n",
    "\n",
    "        preds = []; \n",
    "        for g_idx, g_clfs in enumerate(base_clfs): # loop over groups\n",
    "            print(g_idx)\n",
    "            preds.append(Parallel(n_jobs=4)(delayed(predict_model)(model, Xi) for model in g_clfs))\n",
    "        print(\"\\Base Classifier Prediction Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "\n",
    "\n",
    "        c_preds = []; sub_preds = np.zeros((len(preds), len(Xi)))\n",
    "        for c_idx in range(0, len(preds[0])):  \n",
    "            if len(preds[0][c_idx].shape) > 1: \n",
    "                for t_idx in range(0, preds[0][c_idx].shape[1]):\n",
    "                    for g_idx, this_pred_group in enumerate(preds):  \n",
    "                        sub_preds[g_idx, :] = this_pred_group[c_idx][:, t_idx]\n",
    "                    c_preds.append(np.mean( sub_preds, axis = 0))  \n",
    "            else:\n",
    "                for g_idx, this_pred_group in enumerate(preds): \n",
    "                    sub_preds[g_idx, :] = this_pred_group[c_idx]\n",
    "                c_preds.append(np.mean( sub_preds, axis = 0)) \n",
    "\n",
    "        Xf = pd.concat( (Xi, pd.DataFrame( dict(zip(all_base_clfs[tidx][2], c_preds)), index=Xi.index) ),\n",
    "                     axis = 'columns')\n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    " \n",
    "\n",
    "        s = scalers[tidx]\n",
    "        print('\\nrunning stacker')\n",
    "        pred = Parallel(n_jobs=4)(delayed(predict_model)(model, s.transform(metaFilter(Xf))) \n",
    "                                                       for model in all_clfs[tidx])\n",
    "        sub_preds = np.zeros((len(all_clfs[tidx]), len(Xi)))\n",
    "        for g_idx, clf in enumerate(all_clfs[tidx]):\n",
    "            sub_preds[g_idx, :] = pred[g_idx]\n",
    "        all_preds[y_var] = np.mean(sub_preds, axis = 0)\n",
    "\n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\Prediction Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return all_preds, Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Scores by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.DataFrame(index = X.index)\n",
    "y_trues = y_preds.copy()\n",
    "scores = pd.DataFrame(index = targets, columns = ['score'])\n",
    "for idx, y_var in enumerate(targets):\n",
    "    print(y_var)\n",
    "    s = scalers[idx]\n",
    "    y_pred, y_true =  predictBag(s.transform(metaFilter(all_base_clfs[idx][3])), \n",
    "                                 all_base_clfs[idx][4][y_var], all_base_clfs[idx][5], all_clfs[idx] ) \n",
    "    score = fnae(y_true, y_pred)\n",
    "    print('{}: {:.4f}\\n\\n'.format(y_var, score))\n",
    "    scores.loc[y_var] = score\n",
    "\n",
    "scores.round(4) # MSCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Overall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    weights = pd.DataFrame( index = ALL_TARGETS, data = [.3, .175, .175, .175, .175] )\n",
    "    overall_score = np.sum(scores * weights.values).iloc[0]\n",
    "    age_score = np.mean(scores.iloc[:1]).iloc[0]\n",
    "    other_scores = np.mean(scores.iloc[1:]).iloc[0]\n",
    "\n",
    "    print(np.round(scores,4))\n",
    "    print(\"\\nOverall Score: {:.4f}\".format(overall_score))\n",
    "\n",
    "    print(\"   {:.4f}:  {:.4f} / {:.4f}   {}\".format(overall_score, age_score, other_scores, \n",
    "                          [ np.round(s, 4) for s in scores.score] ))\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos, Xf = predictAll(test_data, all_base_clfs, all_clfs) \n",
    "\n",
    "y_oos = y_oos.reset_index().melt(id_vars = 'Id', value_name = 'Predicted')\n",
    "y_oos.Id = y_oos.Id.astype(str) + '_' + y_oos.variable\n",
    "y_oos.drop(columns = 'variable', inplace=True)\n",
    "\n",
    "y_oos.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
