{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123      # modifiable seed\n",
    "CLF_SS = 1      # sub-sample model types for faster run\n",
    "TARGETS = -1    # which target (0-4) to predict; -1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (15,5.5)\n",
    "\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "if SEED < 0:\n",
    "    np.random.seed(datetime.datetime.now().microsecond)\n",
    "else:\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/kaggle/input/trends-assessment-prediction//loading.csv' does not exist: b'/kaggle/input/trends-assessment-prediction//loading.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b3bbe079df51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/trends-assessment-prediction/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'loading.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfnc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'fnc.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloading\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/kaggle/input/trends-assessment-prediction//loading.csv' does not exist: b'/kaggle/input/trends-assessment-prediction//loading.csv'"
     ]
    }
   ],
   "source": [
    "path = '/media/hiroki/share/kaggle_data/trends-assessment-prediction/'\n",
    "\n",
    "loading =  pd.read_csv(path+ '/' + 'loading.csv').set_index('Id')\n",
    "fnc =  pd.read_csv(path+ '/' + 'fnc.csv').set_index('Id')\n",
    "assert len(loading) == len(fnc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data =  pd.read_csv(path+ '/' + 'train_scores.csv').set_index('Id')\n",
    "\n",
    "data = pd.concat((loading, fnc,  ), axis = 'columns')  \n",
    "test_data = data[~data.index.isin(y_data.index)]\n",
    "\n",
    "X = data.loc[y_data.index] \n",
    "y = y_data \n",
    "groups = np.random.randint(0, 5, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, KFold, ShuffleSplit\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_params = {\n",
    "    'kernel': [  'rbf',  ] , \n",
    "    'C': [ 1, 2, 3, 5, 7, 10, 15, 20, 30, 50, 70, 100, 140, 200, 300  ],\n",
    "    'gamma': [ 'scale'], \n",
    "    'nu': [   0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1] }\n",
    "\n",
    "def trainNuSVR(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = NuSVR(cache_size=1000, tol = 1e-5)\n",
    "    params = nusvr_params        \n",
    "    return trainModel(x, y, groups, clf, params, cv, n_jobs,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_params = { 'alpha': [  1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 3e-2, 0.1, 0.3,   ],\n",
    "                'l1_ratio': [ 0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.95, 0.97, 0.98, 0.99, 1,   ]}\n",
    "\n",
    "def trainENet(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = ElasticNet(normalize = True, selection = 'random', max_iter = 10000, tol = 1e-5 )\n",
    "    return trainModel(x, y, groups, clf, enet_params, cv, n_jobs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnae(y_true, y_pred):\n",
    "    valid = ~np.isnan(y_true)\n",
    "    y_true = y_true[valid]\n",
    "    y_pred = y_pred[valid]\n",
    "    return np.sum(np.abs(y_true - y_pred))/np.sum(y_true)\n",
    "\n",
    "fnae_scorer = make_scorer(fnae, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x, y, groups, clf, params, cv = 0, n_jobs = None, \n",
    "                   verbose=0, splits=None, **kwargs):\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1    \n",
    "\n",
    "    n_iter = 30    \n",
    "        \n",
    "    folds = ShuffleSplit(n_splits = 10, train_size = 0.75, test_size = 0.20)\n",
    "    clf = RandomizedSearchCV(clf, params, cv = folds, n_iter = n_iter, \n",
    "                            verbose = 1, n_jobs = n_jobs, scoring = fnae_scorer)\n",
    "    \n",
    "    f = clf.fit(x, y, groups)\n",
    "    \n",
    "    print(pd.DataFrame(clf.cv_results_['mean_test_score'])); print();  \n",
    "    best = clf.best_estimator_;  print(best)\n",
    "    print(\"Best Score: {}\".format(np.round(clf.best_score_,4)))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanX(X, target):\n",
    "    X = X.copy()\n",
    "    \n",
    "    for col in fnc.columns:\n",
    "        X[col] = X[col] / 300\n",
    "       \n",
    "    return X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBag(n = 3, model_type = trainENet, data = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "\n",
    "    valid = ~y.isnull()\n",
    "    X = X[valid]; y = y[valid]; groups = groups[valid]\n",
    "    \n",
    "    if 'target' in kwargs:\n",
    "        X = cleanX(X, kwargs['target'])\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    clfs = []; preds = []; ys=[]; datestack = []\n",
    "    for group in group_list:\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "        \n",
    "        groups_train = groups[groups != group]\n",
    "\n",
    "        model = model_type \n",
    "        clf = model(x_train, y_train, groups_train, **kwargs) \n",
    "        clfs.append(clf)\n",
    "\n",
    "        predicted = clf.predict(x_holdout)\n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, predicted)  ) )\n",
    "        \n",
    "        preds.append(predicted)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_ho = np.concatenate(ys) \n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\nModel Bag Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBaseClfs(clfs, clf_names, data, target = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "    \n",
    "    X = cleanX(X, target)\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    X_ordered = []; y_ordered = []; groups_ordered =[]  \n",
    "    all_base_clfs = []; base_preds = [[] for i in range(0, 5 * len(clfs))]; \n",
    "    for group in group_list:\n",
    "        print(\"Training Fold {} of {}:\".format(group, len(group_list)))\n",
    "        np.random.seed(SEED)\n",
    "        \n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "\n",
    "        y_idx = ALL_TARGETS.index(target)\n",
    "        \n",
    "        X_ordered.append(x_holdout)\n",
    "        y_ordered.append(y_holdout)\n",
    "        groups_ordered.append(groups[groups == group])\n",
    "        \n",
    "        base_clfs = []\n",
    "        for idx, clf in enumerate(clfs):\n",
    "            base_clfs.append(clone(clf))\n",
    "        \n",
    "        def train_model(model, X, y):\n",
    "            ss = (~pd.DataFrame(y).isnull().any(axis=1))\n",
    "            model.fit(X[ss], y[ss]); return model\n",
    "        \n",
    "        base_clfs = Parallel(n_jobs=4)(delayed(train_model)(model, x_train, y_train[y_var]) for model in base_clfs)\n",
    "        all_base_clfs.append(base_clfs)\n",
    "        \n",
    "        def predict_model(model, X):\n",
    "            o = model.predict(X); return o    \n",
    "        preds = Parallel(n_jobs=4)(delayed(predict_model)(model, x_holdout) for model in base_clfs)\n",
    "        \n",
    "        \n",
    "        pidx = 0; clf_pred_names = []\n",
    "        for idx, clf in enumerate(base_clfs):   \n",
    "            print(\"{:.4f} for {}\".format( \n",
    "                      fnae(y_holdout[target], preds[idx]), clf_names[idx]  ) )\n",
    "            base_preds[pidx].append(preds[idx]); pidx+=1;\n",
    "            clf_pred_names.append(clf_names[idx])\n",
    "            \n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "\n",
    "    base_preds = base_preds[:len(clf_pred_names)]\n",
    "    for idx in range(0, len(base_preds)):\n",
    "        base_preds[idx] = np.concatenate(base_preds[idx])\n",
    "\n",
    "    \n",
    "    print(\"\\Base Classifier Train Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "    return (all_base_clfs, base_preds, clf_pred_names, \n",
    "        pd.concat(X_ordered), pd.concat(y_ordered), np.concatenate(groups_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lassos():\n",
    "    clfs = []; clf_names = []\n",
    "    lassos =  [1e-5, 3e-5, 1e-4,  3e-4,  0.001, 0.003,  0.01,  0.03,  0.1,  0.3,  1, ]\n",
    "    for l in lassos:\n",
    "        clfs.append(Lasso(alpha = l,  selection = 'random', max_iter = 5000, tol = 1e-5))\n",
    "        clf_names.append('Lasso alpha={}'.format(l))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    " \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridges():\n",
    "    clfs = []; clf_names = []\n",
    "    ridges =  [3e-5,  1e-4,  2e-4, 5e-4, 0.001, 0.002, 0.005,  0.01,  0.03,  0.1,  0.3,  1,  3,  10,    ]\n",
    "    for r in ridges:\n",
    "        clfs.append(Ridge(alpha = r, max_iter = 5000, tol = 1e-5))\n",
    "        clf_names.append('Ridge alpha={}'.format(r))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    "\n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVRs():\n",
    "    clfs = []; clf_names = []\n",
    "    svrs =  ([0.2, 1, 7, 50], [1, 3, 7]) \n",
    "    for c in svrs[0]:\n",
    "        for e in svrs[1]:\n",
    "            clfs.append(SVR(C = c, epsilon = e, cache_size=1000, max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('SVR C={}, epsilon={}'.format(c,e))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENets():\n",
    "    clfs = []; clf_names = []\n",
    "    enets = ([3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2  ], [ 0, 0.05, 0.1, 0.5, 0.9, 0.95, 0.98, 1]) \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = False, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet alpha={}, l1_ratio={}'.format(a,l))\n",
    " \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = True, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet-n alpha={}, l1_ratio={}'.format(a,l))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaseClfs(y_var):\n",
    "    idx = ALL_TARGETS.index(y_var)\n",
    "\n",
    "    clfs = []\n",
    "    clf_names = []\n",
    "    \n",
    "    model_sets =  [SVRs(), ENets(), Lassos(), Ridges()]\n",
    "    for model_set in model_sets:\n",
    "        clfs.extend(model_set[0])\n",
    "        clf_names.extend(model_set[1])\n",
    "   \n",
    "\n",
    "    return clfs[::CLF_SS], clf_names[::CLF_SS];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TARGETS = y.columns.to_list()  \n",
    "if isinstance(TARGETS, list):\n",
    "    targets = [ALL_TARGETS[i] for i in TARGETS]\n",
    "elif TARGETS is not None and TARGETS >= 0:\n",
    "    targets = ALL_TARGETS[TARGETS: TARGETS + 1]\n",
    "else:\n",
    "    targets = ALL_TARGETS\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaFilter(X):\n",
    "    return X[[c for c in X.columns if c not in data.columns or c in loading.columns ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clfs = []; all_raw_base_clfs = []; all_base_clfs = []; scalers = []\n",
    "for idx, y_var in enumerate(targets):\n",
    "    print('---Training Models for {}---\\n'.format(y_var))\n",
    "       \n",
    "    \n",
    "    # train base classifiers\n",
    "    raw_base_clfs, base_clf_names = getBaseClfs(y_var)\n",
    "    all_raw_base_clfs.append((raw_base_clfs, base_clf_names))\n",
    "    \n",
    "    base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge = \\\n",
    "                    trainBaseClfs(raw_base_clfs, base_clf_names, \n",
    "                                  data = (X, y, groups), \n",
    "                                  target=y_var, )\n",
    "    Xe = pd.concat( (Xe, pd.DataFrame( dict(zip(base_clf_names, base_clf_preds)), index=Xe.index) ),\n",
    "                     axis = 'columns')\n",
    "    \n",
    "    all_base_clfs.append((base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge ))\n",
    "    \n",
    "    \n",
    "    # train meta model\n",
    "    \n",
    "    if y_var == 'age':\n",
    "        s = FunctionTransformer()\n",
    "        meta_model = trainNuSVR\n",
    "    else:\n",
    "        s = StandardScaler()\n",
    "        meta_model = trainENet\n",
    "     \n",
    "    s.fit(metaFilter(Xe))\n",
    "    scalers.append(s)\n",
    "    \n",
    "    all_clfs.append( runBag(data = (s.transform(metaFilter(Xe)), ye[y_var], ge), # target=y_var,\n",
    "                                   model_type = meta_model) )\n",
    "    # run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def predictBag(X, y, groups, clfs, target = None):\n",
    "    start_time = datetime.datetime.now(); \n",
    "\n",
    "    valid = ~y.isnull()\n",
    "    X = X[valid]; y = y[valid]; groups = groups[valid]\n",
    "    \n",
    "    if target is not None:\n",
    "        X = cleanX(X, target)\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "\n",
    "    preds = []; ys=[]; datestack = []\n",
    "    for idx, group in enumerate(group_list):\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "  \n",
    "        y_pred = clfs[idx].predict(x_holdout)    \n",
    "        preds.append(y_pred)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, y_pred) ) )\n",
    "        \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_true = np.concatenate(ys) \n",
    "    \n",
    "    print(\"\\Bag Prediction Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def predictAll(X_test, all_base_clfs, all_clfs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "        \n",
    "    def predict_model(model, X):\n",
    "        o = model.predict(X)\n",
    "        return o    \n",
    "    \n",
    "    all_preds = pd.DataFrame(columns = targets, index=X_test.index)\n",
    "    for tidx, y_var in enumerate(targets): # loop over targets\n",
    "        print(y_var)\n",
    "        Xi = cleanX(X_test, y_var)\n",
    "        base_clfs = all_base_clfs[tidx][0]\n",
    "         \n",
    "\n",
    "        preds = []; \n",
    "        for g_idx, g_clfs in enumerate(base_clfs): # loop over groups\n",
    "            print(g_idx)\n",
    "            preds.append(Parallel(n_jobs=4)(delayed(predict_model)(model, Xi) for model in g_clfs))\n",
    "        print(\"\\Base Classifier Prediction Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "\n",
    "\n",
    "        c_preds = []; sub_preds = np.zeros((len(preds), len(Xi)))\n",
    "        for c_idx in range(0, len(preds[0])):  \n",
    "            if len(preds[0][c_idx].shape) > 1: \n",
    "                for t_idx in range(0, preds[0][c_idx].shape[1]):\n",
    "                    for g_idx, this_pred_group in enumerate(preds):  \n",
    "                        sub_preds[g_idx, :] = this_pred_group[c_idx][:, t_idx]\n",
    "                    c_preds.append(np.mean( sub_preds, axis = 0))  \n",
    "            else:\n",
    "                for g_idx, this_pred_group in enumerate(preds): \n",
    "                    sub_preds[g_idx, :] = this_pred_group[c_idx]\n",
    "                c_preds.append(np.mean( sub_preds, axis = 0)) \n",
    "\n",
    "        Xf = pd.concat( (Xi, pd.DataFrame( dict(zip(all_base_clfs[tidx][2], c_preds)), index=Xi.index) ),\n",
    "                     axis = 'columns')\n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    " \n",
    "\n",
    "        s = scalers[tidx]\n",
    "        print('\\nrunning stacker')\n",
    "        pred = Parallel(n_jobs=4)(delayed(predict_model)(model, s.transform(metaFilter(Xf))) \n",
    "                                                       for model in all_clfs[tidx])\n",
    "        sub_preds = np.zeros((len(all_clfs[tidx]), len(Xi)))\n",
    "        for g_idx, clf in enumerate(all_clfs[tidx]):\n",
    "            sub_preds[g_idx, :] = pred[g_idx]\n",
    "        all_preds[y_var] = np.mean(sub_preds, axis = 0)\n",
    "\n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\Prediction Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return all_preds, Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Scores by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.DataFrame(index = X.index)\n",
    "y_trues = y_preds.copy()\n",
    "scores = pd.DataFrame(index = targets, columns = ['score'])\n",
    "for idx, y_var in enumerate(targets):\n",
    "    print(y_var)\n",
    "    s = scalers[idx]\n",
    "    y_pred, y_true =  predictBag(s.transform(metaFilter(all_base_clfs[idx][3])), \n",
    "                                 all_base_clfs[idx][4][y_var], all_base_clfs[idx][5], all_clfs[idx] ) \n",
    "    score = fnae(y_true, y_pred)\n",
    "    print('{}: {:.4f}\\n\\n'.format(y_var, score))\n",
    "    scores.loc[y_var] = score\n",
    "\n",
    "scores.round(4) # MSCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Overall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    weights = pd.DataFrame( index = ALL_TARGETS, data = [.3, .175, .175, .175, .175] )\n",
    "    overall_score = np.sum(scores * weights.values).iloc[0]\n",
    "    age_score = np.mean(scores.iloc[:1]).iloc[0]\n",
    "    other_scores = np.mean(scores.iloc[1:]).iloc[0]\n",
    "\n",
    "    print(np.round(scores,4))\n",
    "    print(\"\\nOverall Score: {:.4f}\".format(overall_score))\n",
    "\n",
    "    print(\"   {:.4f}:  {:.4f} / {:.4f}   {}\".format(overall_score, age_score, other_scores, \n",
    "                          [ np.round(s, 4) for s in scores.score] ))\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos, Xf = predictAll(test_data, all_base_clfs, all_clfs) \n",
    "\n",
    "y_oos = y_oos.reset_index().melt(id_vars = 'Id', value_name = 'Predicted')\n",
    "y_oos.Id = y_oos.Id.astype(str) + '_' + y_oos.variable\n",
    "y_oos.drop(columns = 'variable', inplace=True)\n",
    "\n",
    "y_oos.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
